![GitHub stars](https://img.shields.io/github/stars/das-dipanjan/essential-protein-identification-for-cancer-biomarkers?style=social) ![GitHub forks](https://img.shields.io/github/forks/das-dipanjan/essential-protein-identification-for-cancer-biomarkers?style=social) ![GitHub last commit](https://img.shields.io/github/last-commit/das-dipanjan/essential-protein-identification-for-cancer-biomarkers/main)

# ESSENTIAL PROTEIN IDENTIFICATION FOR CANCER BIOMARKERS
🔬Predicting cancer susceptibility using protein interaction networks and machine learning models. 
<br/>

## 📌 **Project Overview**  
This project leverages **biological datasets** and **machine learning algorithms** to predict cancer susceptibility based on **protein-protein interaction networks (PPINs)**. Using **data from DisGeNet and UniProt**, we analyze interactions, visualize networks, and implement **ML models** to identify key cancer-related genes.  

### 🧬 **Key Highlights**  
✅ Compiled **cancer-associated gene data** from **DisGeNet** and **UniProt**  
✅ Used **MOLBIOTOOLS** to generate **Venn diagrams** for gene analysis  
✅ Visualized **protein interaction networks** with **Cytoscape**  
✅ Implemented **8 machine learning models** for cancer prediction  
✅ Achieved high accuracy in detecting **Colon, Gallbladder, and Common Cancers**  

<br/>
<br/>

## 📊 **Dataset Information**  
📁 **Datasets Used**:  
- **Colon Cancer** → `Colon_Positive_PPIN.csv`, `Colon_Negative_PPIN.csv`  
- **Gallbladder Cancer** → `Gallbladder_Positive_PPIN.csv`, `Gallbladder_Negative_PPIN.csv`  
- **Common Cancer** → `Common_Positive_PPIN.csv`, `Common_Negative_PPIN.csv`  
Each dataset contains **protein interaction data** that helps train and evaluate ML models.  

<br/>
<br/>

## 🏗 **Machine Learning Models Implemented**  

| Model | Description |
|--------|------------|
| 🏆 **XGBoost** | Extreme Gradient Boosting for high-performance classification |
| 🎯 **Support Vector Machine (SVM)** | Hyperplane-based classification |
| 📈 **Logistic Regression** | Probabilistic binary classification |
| 🌳 **Decision Tree** | Rule-based classification |
| 🌲 **Random Forest** | Ensemble of decision trees to prevent overfitting |
| 🎰 **Naive Bayes** | Probability-based classification |
| 🔍 **K-Nearest Neighbors (KNN)** | Distance-based classification |
| 🚀 **AdaBoost** | Boosting weak classifiers into a strong model |

<br/>
<br/>

## 🛠 **Tech Stack**  
#### **Programming Language**  
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)  

**Libraries & Frameworks**  
![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white) ![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white) ![XGBoost](https://img.shields.io/badge/XGBoost-EC4D3D?style=for-the-badge&logo=xgboost&logoColor=white) ![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white) ![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white) ![Matplotlib](https://img.shields.io/badge/Matplotlib-11557C?style=for-the-badge&logo=matplotlib&logoColor=white) ![Seaborn](https://img.shields.io/badge/Seaborn-40E0D0?style=for-the-badge) 
 

<br/>
<br/>

## 📌 **Results & Findings**  
📊 **Performance Metrics:**  
- **ROC Curves** plotted for each model to evaluate classification performance  
- **XGBoost** and **Random Forest** outperformed other models with **higher accuracy**  
- **KNN** showed moderate accuracy but was computationally expensive  
- **AdaBoost** improved weak classifiers to yield stable predictions

## Project Report
The project report is uploaded at [this link](https://www.example.com)
## Presentation
![Final Year](https://github.com/user-attachments/assets/18a98d02-efb1-4307-a8fd-ba7f1bc1db98)


## 👨‍💻 **Contributors**  
👤 Dipanjan Das  
👤 Abhishek Saha  
👤 Abir Chakraborty  
👤 Soumalya Karmakar  
👤 Avik Das
